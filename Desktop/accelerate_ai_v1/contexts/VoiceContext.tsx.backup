import React, { createContext, useState, useCallback, useRef, ReactNode, FC, useContext } from 'react';
import { MicrophoneIcon, AlertTriangleIcon, XIcon } from '../components/icons';

interface VoiceContextType {
    isListening: boolean;
    startListening: (onResultCallback: (transcript: string) => void) => void;
    stopListening: () => void;
    error: string | null;
    isSupported: boolean;
}

const VoiceContext = createContext<VoiceContextType | undefined>(undefined);

declare global {
    interface Window {
        SpeechRecognition: any;
        webkitSpeechRecognition: any;
    }
}

export const VoiceProvider: FC<{ children: ReactNode }> = ({ children }) => {
    const [isListening, setIsListening] = useState(false);
    const [error, setError] = useState<string | null>(null);
    const recognitionRef = useRef<any>(null);
    const onResultCallbackRef = useRef<(transcript: string) => void>(() => {});

    const isSupported = typeof window !== 'undefined' && ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window);

    const stopListening = useCallback(() => {
        if (recognitionRef.current) {
            recognitionRef.current.stop();
        }
    }, []);

    const startListening = useCallback(async (onResultCallback: (transcript: string) => void) => {
        if (!isSupported) {
            setError("Voice recognition is not supported in this browser.");
            return;
        }

        if (isListening) {
            stopListening();
            return;
        }

        setError(null);

        // Explicitly request microphone permission to provide better error messages.
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            // Stop the track immediately once permission is granted, as we don't need the stream itself.
            stream.getTracks().forEach(track => track.stop());
        } catch (err) {
            if (err instanceof DOMException) {
                if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                    setError('Microphone access was denied. Please allow microphone access in your browser settings to use this feature.');
                } else if (err.name === 'NotFoundError') {
                     setError('No microphone was found. Please ensure your microphone is connected.');
                } else {
                     setError(`Could not access microphone: ${err.message}. Please ensure it is not in use by another application.`);
                }
            } else {
                 setError('An unknown error occurred while trying to access the microphone.');
            }
            return;
        }

        onResultCallbackRef.current = onResultCallback;

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognitionRef.current = new SpeechRecognition();
        const recognition = recognitionRef.current;
        
        recognition.continuous = true; // Allow for pauses
        recognition.interimResults = false;
        recognition.lang = 'en-US';

        recognition.onstart = () => {
            setIsListening(true);
        };

        recognition.onerror = (event: any) => {
            let errorMessage = `An unknown error occurred (${event.error}).`;
            switch (event.error) {
                case 'no-speech':
                    errorMessage = 'No speech was detected. Please try again.';
                    break;
                case 'audio-capture':
                    errorMessage = 'Audio capture failed. Please ensure your microphone is connected and working correctly.';
                    break;
                case 'not-allowed':
                    // This case is now largely handled by the getUserMedia check above, but is kept as a fallback.
                    errorMessage = 'Microphone access was denied. Please allow microphone access in your browser settings to use this feature.';
                    break;
                case 'network':
                    errorMessage = 'A network error occurred with the browser\'s speech recognition service. This might be a temporary issue. Please check your internet connection and try again.';
                    break;
                default:
                    // Keep the default error message for unhandled cases
                    break;
            }
            setError(errorMessage);
            setIsListening(false);
        };

        recognition.onend = () => {
            setIsListening(false);
            recognitionRef.current = null;
        };

        recognition.onresult = (event: any) => {
            let transcript = '';
            // Concatenate all new final results since the last event
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                transcript += event.results[i][0].transcript;
            }

            if (onResultCallbackRef.current && transcript.trim()) {
                onResultCallbackRef.current(transcript.trim());
            }
            // `stopListening()` is intentionally removed here.
            // The user must click the button again or wait for a longer timeout to stop.
        };
        
        try {
            recognition.start();
        } catch(e) {
            console.error("Error starting speech recognition:", e);
            setError("Could not start voice recognition. This can sometimes happen if another tab is already using the microphone.");
            setIsListening(false);
        }

    }, [isSupported, isListening, stopListening]);


    const value = {
        isListening,
        startListening,
        stopListening,
        error,
        isSupported
    };

    return (
        <VoiceContext.Provider value={value}>
            {children}
            {isListening && (
                <div className="fixed bottom-5 right-5 bg-red-600 text-white rounded-full p-4 shadow-lg flex items-center gap-3 z-50 animate-pulse">
                    <MicrophoneIcon className="h-6 w-6" />
                    <span>Listening...</span>
                </div>
            )}
            {error && (
                <div className="fixed bottom-5 left-5 bg-red-800 text-white rounded-lg p-4 shadow-lg flex items-start gap-3 z-50 max-w-sm">
                    <AlertTriangleIcon className="h-6 w-6 flex-shrink-0 mt-0.5" />
                    <div>
                        <p className="font-bold">Voice Input Error</p>
                        <p className="text-sm">{error}</p>
                    </div>
                    <button onClick={() => setError(null)} className="ml-auto -mr-2 -my-2 p-2 rounded-full hover:bg-red-700 transition-colors">
                        <XIcon className="h-5 w-5" />
                    </button>
                </div>
            )}
        </VoiceContext.Provider>
    );
};

export const useVoiceRecognition = (): VoiceContextType => {
    const context = useContext(VoiceContext);
    if (context === undefined) {
        throw new Error('useVoiceRecognition must be used within a VoiceProvider');
    }
    return context;
};